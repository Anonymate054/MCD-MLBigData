{"cells":[{"cell_type":"markdown","id":"47526a2d","metadata":{"id":"47526a2d"},"source":["# Online PCA\n","\n","Los métodos para la reducción de dimensiones, en especial los métodos del tipo __online__, siguen siendo un campo de investigación.\n","\n","En específico, PCA tiene varios métodos que intentan competir por convertirse en estandard. En este notebook vamos a ver uno de los métodos más populares llamado __incremental pca__."]},{"cell_type":"code","execution_count":null,"id":"0551f2ef","metadata":{"id":"0551f2ef"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","#--para cargar los datos\n","from sklearn.datasets import load_iris\n","\n","#--funciones relacionadas a PCA\n","from sklearn.decomposition import PCA, IncrementalPCA"]},{"cell_type":"code","source":["#--cargamos los datos\n","iris = load_iris()\n","\n","#--atributos: los datos a los que reduciremos las dimensiones\n","X = iris.data\n","#--variable respuesta: la utilizó solo para fines didacticos al\n","# mostrar la respuesta\n","y = iris.target\n","\n","X[:5, ]"],"metadata":{"id":"IcsE5OBNV-SX"},"id":"IcsE5OBNV-SX","execution_count":null,"outputs":[]},{"cell_type":"code","source":["#--definimos el número de dimensiones objetivo\n","n_components = 2"],"metadata":{"id":"uHRby_haXDQ-"},"id":"uHRby_haXDQ-","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Calculamos PCA \"normal\" para comparar el resultado con el algoritmo PCA en línea."],"metadata":{"id":"XGgQ9rcAWo1P"},"id":"XGgQ9rcAWo1P"},{"cell_type":"code","source":["#--definimos una instancia de PCA\n","pca = PCA(n_components=n_components)\n","\n","#--calculamos la reducción\n","X_pca = pca.fit_transform(X)"],"metadata":{"id":"oj2yE04lWm_f"},"id":"oj2yE04lWm_f","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Primero, vamos a utilizar __incremental PCA__ en todo el data set cargado en memoria.\n","\n","¿Porqué desearíamos hacer lo anteior si ya existe la función __PCA__? Dependiendo del tamaño de __batch_size__, incremental PCA puede ser más eficiente que PCA en terminos de uso de memoria, además de que permite el uso de _sparse arrays_.\n","\n","Por default el __batch_size__ se define como 5 veces el número de atributos. El cuál es un buen balance en terminos de precisión de la respuesta y uso de memoria."],"metadata":{"id":"7lus3wiaXhJN"},"id":"7lus3wiaXhJN"},{"cell_type":"code","execution_count":null,"id":"ffa70647","metadata":{"id":"ffa70647"},"outputs":[],"source":["#--entrenamos y transformamos los datos con incremental PCA\n","ipca = IncrementalPCA(n_components=n_components, batch_size=10)\n","\n","X_ipca = ipca.fit_transform(X)"]},{"cell_type":"markdown","source":["Finalmente utilizamos __partial_fit__ cuando entrenemos el algoritmo en línea."],"metadata":{"id":"IY9ROd1hZtbc"},"id":"IY9ROd1hZtbc"},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"2H-jH88aeb9i"},"id":"2H-jH88aeb9i","execution_count":null,"outputs":[]},{"cell_type":"code","source":["#--leemos el archivo desde un csv para leerlo por partes\n","file_iris = '/content/drive/MyDrive/data_sets/iris.csv'\n","\n","#--definimos una instancia de ipca\n","ipca2 = IncrementalPCA(n_components=n_components)\n","\n","#--realizamos el entrenamiento\n","reader = pd.read_csv(file_iris, iterator = True)\n","n = 0 #--contar el número de filas\n","try:\n","    #--iteramos hasta el final\n","    while reader:\n","        X_batch = reader.get_chunk(10)\n","        ipca2.partial_fit(X_batch.values[:,:4])\n","        n += X_batch.shape[0]\n","except StopIteration:\n","    pass\n","finally:\n","    del reader\n","\n","#--transformamos los datos\n","reader = pd.read_csv(file_iris, iterator = True)\n","i = 0 #--indice auxiliar para rellenar el resultado\n","X_reduced = np.zeros((n,2))\n","try:\n","    #--iteramos hasta el final\n","    while reader:\n","        X_batch = reader.get_chunk(10)\n","        X_reduced[i:(i+X_batch.shape[0]), :] = ipca2.transform(X_batch.values[:,:4])\n","        i += X_batch.shape[0]\n","except StopIteration:\n","    pass\n","finally:\n","    del reader"],"metadata":{"id":"gM7UQh81Zr4t"},"id":"gM7UQh81Zr4t","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Comparamos los resultados por medio de gráficas las dimensiones reducidas."],"metadata":{"id":"Cu13SMYoakC8"},"id":"Cu13SMYoakC8"},{"cell_type":"code","execution_count":null,"id":"c0981226","metadata":{"id":"c0981226"},"outputs":[],"source":["#--definimos un color para cada clase. Recordemos que iris dataset tiene tres clases\n","colors = ['navy', 'turquoise', 'darkorange']\n","\n","j = 1\n","plt.figure(figsize=(15,6))\n","for X_transformed, title in [(X_pca, \"PCA\"), (X_ipca, \"Incremental PCA\"), (X_reduced, \"Incremental PCA online\")]:\n","    plt.subplot(1,3,j)\n","    for color, i, target_name in zip(colors, [0, 1, 2], iris.target_names):\n","        plt.scatter(X_transformed[y == i, 0], X_transformed[y == i, 1],\n","                    color=color, lw=2, label=target_name)\n","\n","    j = j+1\n","    if \"online\" in title:\n","        err = np.abs(np.abs(X_pca) - np.abs(X_reduced)).mean()\n","        plt.title(title + \" del iris dataset\\n Error absoluto promedio \"\n","                  \"%.4f\" % err)\n","    elif \"Incremental\" in title:\n","        err = np.abs(np.abs(X_pca) - np.abs(X_ipca)).mean()\n","        plt.title(title + \" del iris dataset\\n Error absoluto promedio \"\n","                  \"%.4f\" % err)\n","    else:\n","        plt.title(title + \" del iris dataset\")\n","\n","    plt.legend(loc=\"best\")\n","    plt.axis([-4, 4, -1.5, 1.5])\n","\n","plt.show()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.13"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}