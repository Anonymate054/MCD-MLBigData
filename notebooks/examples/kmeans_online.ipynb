{"cells":[{"cell_type":"markdown","id":"2554535b","metadata":{"id":"2554535b"},"source":["# K-means online\n","\n","En este notebook se desmuestra como utilizar el algoritmo k-means en línea.\n","\n","Utilizaremos el algoritmo \"común\" usando la librería de sklearn para utilizarlo como base de comparación.\n","\n","Describiremos dos algoritmos de k-means en línea:\n","* Usando solamente numpy\n","* Usando sklearn pero usando mini batches de datos"]},{"cell_type":"code","execution_count":null,"id":"a7ca0fd9","metadata":{"id":"a7ca0fd9"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","#--para crear un dataset artificial\n","from sklearn.datasets import make_blobs\n","\n","#--para utilizar las funciones de sklearn relacionadas con K-means\n","from sklearn.cluster import KMeans\n","from sklearn.cluster import MiniBatchKMeans"]},{"cell_type":"markdown","id":"3852b212","metadata":{"id":"3852b212"},"source":["Generamos tres datasets con diferentes características con el objetivo de estudiar el desempeño de los algoritmos. Los dos primeros datasets tendran clusters bien definidos y el tercero tendra clusters que se entrelazan entre si."]},{"cell_type":"code","execution_count":null,"id":"7bd133c4","metadata":{"id":"7bd133c4"},"outputs":[],"source":["#--número de muestras a generar\n","num_muestras = 1000\n","\n","#--2 clusters bien definidos\n","X_a, y_a = make_blobs(n_samples = 1000, n_features = 2, centers = [[3,3],[7,7]], random_state=0)\n","\n","#--4 clusters bien definidos\n","X_b, y_b = make_blobs(n_samples = 1000, n_features = 2, centers = [[1,1],[7,7], [10,0], [0,12]],\n","                      random_state=0)\n","\n","#--4 clusters con traslape\n","X_c, y_c = make_blobs(n_samples = 1000, n_features = 2, centers = 4, random_state=0)\n","\n","#--ploteamos los datasets que vamos a utilizar\n","plt.figure(figsize=(15,5))\n","plt.subplot(1,3,1)\n","plt.scatter(X_a[:,0], X_a[:,1], marker='o', c = y_a)\n","plt.subplot(1,3,2)\n","plt.scatter(X_b[:,0], X_b[:,1], marker='o', c = y_b)\n","plt.subplot(1,3,3)\n","plt.scatter(X_c[:,0], X_c[:,1], marker='o', c = y_c)\n","plt.show()"]},{"cell_type":"markdown","id":"fb58ad12","metadata":{"id":"fb58ad12"},"source":["Utilizamos el algoritmo \"comun\" de k-means (la versión que __no__ es online) desde la libería de sklearn para tener una referencia del desempeño.\n","\n","Además, asumimos que sabemos el número de clusters, en la práctica podríamos utilizar el método del \"codo\" para inferir el número de clusters."]},{"cell_type":"code","execution_count":null,"id":"c6eb6abe","metadata":{"id":"c6eb6abe"},"outputs":[],"source":["#--primer dataset\n","model = KMeans(n_init=5, n_clusters = 2)\n","model.fit(X_a)\n","\n","plt.figure(figsize=(15, 5))\n","plt.subplot(1,3,1)\n","plt.scatter(X_a[:,0], X_a[:,1], marker='o', c=model.labels_)\n","\n","#--segundo dataset\n","model = KMeans(n_init=5, n_clusters = 4)\n","model.fit(X_b)\n","plt.subplot(1,3,2)\n","plt.scatter(X_b[:,0], X_b[:,1], marker='o', c=model.labels_)\n","\n","#--tercer dataset\n","model = KMeans(n_init=5, n_clusters = 4)\n","model.fit(X_c)\n","plt.subplot(1,3,3)\n","plt.scatter(X_c[:,0], X_c[:,1], marker='o', c=model.labels_)\n","plt.show();"]},{"cell_type":"markdown","id":"69eaa5f2","metadata":{"id":"69eaa5f2"},"source":["# K-means online\n","\n","Utilizaremos los mismos datasets, estan cargados en memoria, sin embargo los entrenaremos usando solo algunas muestras a la vez, tal como lo haríamos si tuvieramos que cargar el dataset en memoria poco a poco.\n","\n","\n","## Usando solamente numpy"]},{"cell_type":"code","execution_count":null,"id":"750bae74","metadata":{"id":"750bae74"},"outputs":[],"source":["# genero un indice aleatorio para permutar las filas y obtener diferentes\n","# respuestas cada vez que corro el algoritmo\n","\n","idx = np.random.permutation(num_muestras)\n","\n","#--actualizar estas variables dependiendo del data set que vayamos o ocupar.\n","num_clusters = 4\n","X = X_c[idx, :]\n","y = y_c[idx]\n","\n","\n","#--seleccionamos \"num_clusters\" muestras de forma aleatoria para inicializar\n","# los clusters. Asumimos que nuestro dataset no esta ordenado, entonces podemos\n","# utilizar las primeras muestras para inicializar los clusters.\n","#mu = X[np.random.randint(num_muestras, size=(num_clusters)), :].copy()\n","mu = X[:num_clusters, :].copy()\n","#--definimos una variable para llevar la cuenta de las muestras\n","n = np.zeros(num_clusters)\n","#--definimos una lista donde guardar la asignación de cada muestra a su cluster\n","y_hat = []\n","for i in range(num_muestras):\n","    #--distancia euclidiana de la muestra a los clusters\n","    d2 = np.sum((X[i,:] - mu)**2, axis=1)\n","    #--escoger el cluster mas cercano\n","    closest_cl = np.argmin(d2)\n","    #--actualizar las variables\n","    n[closest_cl] = n[closest_cl] + 1\n","    mu[closest_cl] = mu[closest_cl] + (1/n[closest_cl])*(X[i,:] - mu[closest_cl, :])\n","    #--guardamos el resultado\n","    y_hat.append(closest_cl)\n","\n","#--prediccion\n","plt.scatter(X[:,0], X[:,1], marker='o', c=y_hat)\n","plt.scatter(mu[:,0], mu[:,1], marker='*', c = 'r', s=200)\n","plt.show()"]},{"cell_type":"markdown","id":"938d5694","metadata":{"id":"938d5694"},"source":["## MiniBatchKMeans\n","\n","Finalmente vamos a utilizar una función de sklearn que nos permite hacer el entrenamiento en línea."]},{"cell_type":"code","execution_count":null,"id":"b50e1f16","metadata":{"id":"b50e1f16"},"outputs":[],"source":["#--definimos el tamaño de cada mini-batch\n","mini_batch = 10\n","\n","#--para el primer dataset\n","#--definición del modelo\n","modelo = MiniBatchKMeans(n_clusters = 2, random_state = 0, batch_size = mini_batch, n_init='auto')\n","#--entrenamiento\n","for i in range(mini_batch, num_muestras, mini_batch):\n","    X_batch = X_a[:i,]\n","    modelo.partial_fit(X_batch)\n","#--prediccion\n","y_hat = modelo.predict(X_a)\n","#--ploteo\n","plt.figure(figsize=(15, 5))\n","plt.subplot(1,3,1)\n","plt.scatter(X_a[:,0], X_a[:,1], marker='o', c=y_hat)\n","\n","#--para el segundo dataset\n","#--definición del modelo\n","modelo = MiniBatchKMeans(n_clusters = 4, random_state = 0, batch_size = mini_batch, n_init='auto')\n","#--entrenamiento\n","for i in range(mini_batch, num_muestras, mini_batch):\n","    X_batch = X_b[:i,]\n","    modelo.partial_fit(X_batch)\n","#--prediccion\n","y_hat = modelo.predict(X_b)\n","#--ploteo\n","plt.subplot(1,3,2)\n","plt.scatter(X_b[:,0], X_b[:,1], marker='o', c=y_hat)\n","\n","#--para el tercer dataset\n","#--definición del modelo\n","modelo = MiniBatchKMeans(n_clusters = 4, random_state = 0, batch_size = mini_batch, n_init='auto')\n","#--entrenamiento\n","for i in range(mini_batch, num_muestras, mini_batch):\n","    X_batch = X_c[:i,]\n","    modelo.partial_fit(X_batch)\n","#--prediccion\n","y_hat = modelo.predict(X_c)\n","#--ploteo\n","plt.subplot(1,3,3)\n","plt.scatter(X_c[:,0], X_c[:,1], marker='o', c=y_hat)\n","plt.show()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.13"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}