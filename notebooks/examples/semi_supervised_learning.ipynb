{"cells":[{"cell_type":"markdown","metadata":{"id":"FQrE2xiLDEDD"},"source":["# Semi-supervised classification: Spam email recognition\n","\n","En este notebook demostramos como podemos utilizar aprendizaje semi-supervisado para entrenar un modelo cuando tenemos pocas muestras con etiquetas.\n","\n","Especificamente utilizaremos la técnica conocida como \"self-labeling\", la cuál utiliza un clasificador base para incrementar, de forma iterativa, las etiquetas por medio de usar las predicciones donde el clasificador se siente con mayor confianza y usarlas como etiquetas \"reales\" para la siguiente iteración.\n","\n","La solución que presentamos a continuación esta basada en usar un algoritmo de la MLlib, es decir, es una solución \"global\"."]},{"cell_type":"code","source":["!pip install pyspark"],"metadata":{"id":"bkndh2MG1gDO"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FuDY-SVyDEDL"},"outputs":[],"source":["import numpy as np\n","\n","from pyspark.sql import SparkSession\n","import pyspark.sql.functions as F\n","\n","from pyspark.ml.feature import VectorAssembler\n","from pyspark.ml.classification import DecisionTreeClassifier\n","from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n","from pyspark.ml.functions import vector_to_array"]},{"cell_type":"code","source":["spark = SparkSession.builder\\\n","                    .master(\"local[*]\")\\\n","                    .appName(\"aprendizaje_semi_supervised\")\\\n","                    .getOrCreate()\\\n","\n","sc = spark.sparkContext"],"metadata":{"id":"Ds7diwEmJTW5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#--otorgamos acceso a google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"L7trZ25o14bZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Utilizaremos el conjunto de datos __spambase.csv__ con el objetivo de entrenar un clasificador que pueda distinguir entre correos de genuinos y spam.\n","\n","El conjunto de datos contiene __4601__ instnacias o filas, __57__ atributos y la variable respuesta.\n","\n","Los atributos contienen entre otras cosas, una medida de repetición de palabras, longitud de palabras, etc. Todos los atributos son númericos.\n","\n","La última columna contiene a la variable respuesta."],"metadata":{"id":"iAzeRuXq46eT"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"y0XGgb30DEDN"},"outputs":[],"source":["PATH_INPUT = '/content/drive/MyDrive/data_sets/spambase.csv'\n","\n","df = spark.read.format('csv')\\\n","    .option(\"header\", 'false')\\\n","    .load(PATH_INPUT)\n","\n","print(f'Número de instancias: {df.count()}')\n","print(f'Número de columnas: {len(df.columns)}')\n","df.show(3)"]},{"cell_type":"markdown","source":["### Pre-procesamiento y división de nuestro conjunto de datos"],"metadata":{"id":"zFQ0qCzKAkvt"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"qDhWdMLTDEDO"},"outputs":[],"source":["#--De momento, solo nos interesa tener control de la variable respuesta,\n","# por lo que la vamos a renombrar\n","df = df.withColumnRenamed(\"_c57\", \"output\")\n","\n","#--Dado que MLlib solo recive vectores de tipo float, convertimos todo\n","# a float de una vez\n","df = df.select([F.col(c).cast(\"float\").alias(c) for c in df.columns])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FS6EnVSYDEDP"},"outputs":[],"source":["#--Dividimos nuestro datos en entrenamiento y prueba\n","seed = 12345\n","train, test = df.randomSplit([0.7, 0.3], seed)"]},{"cell_type":"markdown","source":["Medimos cuantas instancias tenemos de cada clase:"],"metadata":{"id":"VZirDnbfBW_6"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"_59fCFhLDEDQ"},"outputs":[],"source":["#--contamos las instancias por clase\n","stats = train\\\n","    .groupBy(\"output\")\\\n","    .count()\n","\n","#--calculamos el porcentaje\n","stats = stats\\\n","    .select(\"*\",\n","            F.round((stats[\"count\"] / train.count() * 100), 2).alias(\"ratio(%)\"),\n","    )\n","\n","stats.show()"]},{"cell_type":"markdown","source":["En este caso tenemos casi un 40% de la clase spam, además de que todas las instancias tienen etiqueta. Para utilizar el algoritmo de aprendizaje semi supervisado vamos a simular que tenemos pocas instancias con etiquetas.\n","\n","Creamos una columna nueva que solo contenga un aproximado de 2% de etiquetas."],"metadata":{"id":"i41nofh7Cmjx"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"UwIoTwhaDEDR"},"outputs":[],"source":["#--definimos la porcentaje de etiquetas que deseamos\n","pct = 0.02\n","\n","#--agregamos una nueva columna con solo el 2% de etiquetas.\n","# Para identificar muestras que no tiene etiquetas utilizamos el número 2\n","train = train\\\n","    .withColumn(\"label\",\n","                F.when(F.rand(seed=12345) < pct, train.output).otherwise(2),\n","    )"]},{"cell_type":"code","source":["train.sample(.1).show(3)"],"metadata":{"id":"otqTaBTHKt6y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Revisamos la distribución de las etiquetas:"],"metadata":{"id":"FcKo9GE1IOKV"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"t0x9iS__1buh"},"outputs":[],"source":["stats = train\\\n","    .groupBy(\"label\")\\\n","    .count()\n","\n","stats = stats.select(\"*\",\n","    F.round((stats[\"count\"] / train.count() * 100), 2).alias(\"ratio(%)\"),\n","    )\n","\n","stats\\\n","  .sort(\"label\")\\\n","  .show()"]},{"cell_type":"markdown","metadata":{"id":"vDoMY0NaDEDS"},"source":["### Definir el modelo base para compración\n","\n","Debido a que conocemos todas las etiquetas del conjunto de datos, podemos generar experimentos para conocer como se compara el algoritmo semi-supervisado contra su contraparte \"normal\".\n","\n","En especifico podemos generar un \"límite inferior\", es decir, el desempeño cuando el algoritmo se entrena con poca data. Esperaríamos que el algoritmo semi-supervisado tenga un desempeño mejor a este límite.\n","\n","De la misma forma, utilizando todas las etiquetas reales podemos generar un \"límite superior\". Esperamos que en el mejor de los casos el algoritmo semi-supervisado este alrededor de estos valores."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OcfelNJXDEDT"},"outputs":[],"source":["#--definimos un objeto que obtenga el vector de atributos\n","feature_cols = train.columns\n","feature_cols.remove('output')\n","feature_cols.remove('label')\n","\n","assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lFO7FSfkDEDU"},"outputs":[],"source":["#--transformamos nuestros datos de entrenamiento y prueba\n","train_features = assembler.transform(train)\n","test_features = assembler.transform(test)"]},{"cell_type":"code","source":["train_features.show(3)"],"metadata":{"id":"7_2_qNK0MayB"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IUbIw4t5DEDU"},"outputs":[],"source":["#--ejemplo del vector de atributos. Es un sparse vector.\n","train_features.select(\"features\", \"label\").show(1, truncate = False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q17gnhQiDEDV"},"outputs":[],"source":["#--debido a que estaremos accediendo varias a veces a estos datos, los cargamos\n","# en memoria.\n","# La columna \"output\" la vamos a utilizar para medir métricas de desempeño al\n","# final.\n","train_features = train_features\\\n","    .select(\"features\", \"output\", \"label\")\\\n","    .cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o6vOGVOODEDV"},"outputs":[],"source":["#--dividimos el conjunto de datos en aquellos que tiene \"etiqueta\" y los que no.\n","labeled = train_features\\\n","    .filter(train_features.label != 2.0)\n","\n","unlabeled = train_features\\\n","    .filter(train_features.label == 2.0)"]},{"cell_type":"markdown","source":["### Límite inferior"],"metadata":{"id":"6AUV9uBUOtmZ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"N0AItWuzDEDW"},"outputs":[],"source":["#--definimos un arbol de decisión\n","dt = DecisionTreeClassifier(maxDepth=5,\n","                            labelCol=\"label\")\n","#--lo entrenamos solo con el approx. 2% de nuestros datos\n","model = dt.fit(labeled)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VLF8omedDEDX"},"outputs":[],"source":["#--realizamos predicciones en set de entrenamiento sin etiquetas y en el set\n","# de pruebas\n","pred_unlabeled = model\\\n","    .transform(unlabeled)\n","\n","pred_test = model\\\n","    .transform(test_features)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0AP-RKY4DEDY"},"outputs":[],"source":["#--definimos el objeto que evaluara la predicciones\n","evaluator = MulticlassClassificationEvaluator(\n","    predictionCol=\"prediction\",\n","    labelCol=\"output\",\n","    metricName=\"accuracy\",\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G7PNNAYlDEDY"},"outputs":[],"source":["#--predicciones en set de entrenamiento sin etiqueta\n","temp = evaluator.evaluate(pred_unlabeled)\n","print(f'Precisión conjunto entrenamiento sin etiquetas: {temp:.3}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a7Ngol8xDEDY"},"outputs":[],"source":["temp = evaluator.evaluate(pred_test)\n","print(f'Precisión conjunto de prueba: {temp:.3}')"]},{"cell_type":"markdown","source":["### Límite superior\n","\n","Utilizamos todos los datos etiquetados del conjunto de entrenamiento disponibles para darnos una idea de cuál sería el tope en desempeño que pudiera alcanzar el algoritmo semi-supervisado."],"metadata":{"id":"Iy3xGqb0QZ29"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"QtcPOwKLDEDZ"},"outputs":[],"source":["#--cambiamos la columna de variable respuesta al modelo\n","dt.setLabelCol('output')\n","\n","#--entrenamos el modelo\n","upperbound_model = dt.fit(train_features)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W6i9Rx2-DEDZ"},"outputs":[],"source":["#--realizamos las predicciones en el set de prueba\n","upperbound_pred = upperbound_model.transform(test_features)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c5zZh9taDEDZ"},"outputs":[],"source":["temp = evaluator.evaluate(upperbound_pred)\n","print(f'Precisión conjunto de prueba: {temp:.3}')"]},{"cell_type":"markdown","metadata":{"id":"PFREx5AODEDZ"},"source":["## Algoritmo semi-supervisado: diseño distribuido\n","\n","Dado los supuestos de nuestro experimento:\n","* pocos datos con etiquetas (approx. 2%),\n","* muchos datos sin etiquetas,\n","\n","al inicio el algoritmo tendrá una carga computacional cargada hacia la etapa de predicción y definición de las nuevas etiquetas. Al avanzar las iteraciones, tendremos más datos etiquetados por lo que el entrenamiento empezará a tener una carga más grande y las instancias con etiquetas tenderán a disminuir.\n","\n","Si pensamos en una solución distribuida, debemos tener en consideración con la carga de trabajo pasa de un proceso al otro.\n","\n","Al poner todos los datos dentro de un spark dataframe y utilizar un algoritmo de la MLlib, estamos asegurando que las dos fases __entrenamiento__ y __predicción__ se calculen de forma distriubida.\n","\n","Dependiendo del tipo de problema, puede pasar que al inicio y al final tengamos muy pocas instancias para entrenar y para predecir respectivamente por lo que los recursos de spark pudieran ser demasiados para esos escenarios. Es un precio que podemos pagar por la ventaja de entrenar y predecir en modo distribuido.\n","\n","La solución constará de los siguientes pasos:\n","1. Entrenar un modelo \"global\" usando solo las instancias que tienen etiquetas.\n","2. Predecir las instancias del conjunto de entrenamiento que no tiene etiqueta.\n","3. Decidir cuales son las predicciones que son suficientemente confiables para utilizarlas como instancias con etiqueta la siguiente iteración."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WTl8olrx1buk"},"outputs":[],"source":["#--observamos como el modelo que estamos usando nos regresa las predicciones.\n","# Notesé que \"model\" fue el modelo que entrenamos solo con el 2% de las\n","# instancias\n","preds = model\\\n","    .transform(train_features)\n","\n","preds\\\n","    .select('prediction', 'probability')\\\n","    .show(3, False)"]},{"cell_type":"markdown","source":["Necesitamos elegir las predicciones que el clasificador considera son las más confiables para incorporarlas como etiquetas en la siguiente iteración.\n","\n","Necesitamos obtener la predicción con mayor probabilidad del vector contenido en la columna \"probability\"."],"metadata":{"id":"r_tu6luk0stn"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"BQ23-Kvl1buk"},"outputs":[],"source":["#--separamos las columnas y escogemos la de mayor probabilidad\n","preds = preds.withColumn(\n","    \"prob\", F.array_max(vector_to_array(\"probability\"))\n","  )\n","\n","preds.show(3)"]},{"cell_type":"markdown","source":["Tenemos que decidir el concepto de __predicciones confiables__. Para este ejemplo, dado que estamos utilizando árboles podemos definir __predicciones confiables__ como aquellas que sean igual a __1__.\n","\n","Esta decisión depende del algoritmo y puede pasar que para otros algoritmos diferentes a los árboles proababilidad a 1 sea imposible de obtener. Este es un hyper-parámetro que tenemos que definir.\n","\n","No podemos agregar a las etiquetas todas las instancias que obtuvieron una probabilidad de __1__ porque podemos sesgar el algoritmo hacia alguna clase. Por tanto tenemos que agregar las muestras en base a la distribución de etiquetas originales."],"metadata":{"id":"CAqUF3-t1qPV"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"-B_7c68HDEDd"},"outputs":[],"source":["#--observamos la distribución de las predicciones \"confiables\".\n","preds\\\n","    .filter(\"prob == 1\")\\\n","    .groupBy(\"prediction\")\\\n","    .count()\\\n","    .show()"]},{"cell_type":"markdown","source":["El resultado anterior muestra que el clasificador tiene más confianza prediciendo la clase positiva que en el fenómeno original es precisamente lo opuesto, la clase con menos instancias.\n","\n","Tenemos que definir una forma de asegurarnos que la selección de instancia a incorporarse como \"etiquetas\" tiene la misma distribución que el fenómeno original para cada una de las iteraciones."],"metadata":{"id":"LPVOGqAM3HBO"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"oC3k_iO91buk"},"outputs":[],"source":["#--definimos una función que dada la distribución de clases del fenómeno y\n","# dado el número de instancias por clase con predicción igual a 1, nos regrese\n","# el número correcto de instancias a tomar como predicciones confiables de\n","# cada clase.\n","\n","def instances_per_class(class_distrib, counts):\n","    # La función trabaja con respecto a la clase que esta menos representada\n","\n","    index_min = np.argmin(counts / class_distrib)\n","\n","    new_counts = counts[index_min] * (\n","        class_distrib / class_distrib[index_min]\n","    )\n","\n","    return np.round(new_counts).astype(\"int\")"]},{"cell_type":"markdown","source":["Vamos a probar la función anterior. Para ello vamos a definir una función más que nos regrese la distribución de clases en el conjunto de datos que si tienen etiqueta"],"metadata":{"id":"OKHv8Y4v509g"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"QBfc7szQ1buk"},"outputs":[],"source":["def df_count(df, group_col):\n","    return np.array(\n","              df\\\n","                .groupBy(group_col)\\\n","                .count()\\\n","                .sort(group_col)\\\n","                .toPandas()[\"count\"],\n","              dtype=\"int\",\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NTIXRTIo1bul"},"outputs":[],"source":["#--para probar la función anterior, calculamos la distribución del conjunto\n","# que si tiene etiquetas.\n","class_distrib = df_count(labeled, 'output')\n","class_distrib"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UbGSTs-e1bul"},"outputs":[],"source":["#--obtenemos la cuenta de las predicciones que son \"confiables\"\n","counts = df_count(preds.filter(\"prob == 1\"), \"prediction\")\n","counts"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D0jthb5kDEDe"},"outputs":[],"source":["#--usamos la funcion instances_per_class para obtener el número de\n","# instancias correctas dada la distribución de clases de las etiquetas y el\n","# número de predicciones confiables\n","\n","to_add = instances_per_class(class_distrib, counts)\n","to_add"]},{"cell_type":"markdown","source":["Ya tenemos el número exacto de instancias que debemos agregar como etiquetas \"reales\" para la próxima iteración.\n","\n","Para realizarlo vamos a agregar una nueva columna que incluya las etiquetas de la iteración anterior y las que deseamos agregar. Para crear esta columna notamos que las instancias nuevas que se incorporán como etiquetas reales,  cumplen con las siguientes características:\n","\n","1. No tenían etiqueta, \"label == 2\"\n","2. Obtuvieron una predicción confiable, prob.==1\n","3. Seleccionadas de forma aleatoria de acuerdo a __to_add__\n","\n","Desafortunadamente si deseamos cumplir con el número exacto de muestras a agregar vamos a incorporar complejidad computacional. Una forma simple de acerco es utilizar la misma idea que usamos para reducir el número de etiquetas al inicio, la desventaja es que no será exacta el número de instancias que agregemos.\n","\n","Consideremos las siguientes proporciones:"],"metadata":{"id":"wauHy31h-XQq"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"IJUJwksb1bul"},"outputs":[],"source":["pcts = to_add / counts # elementwise operation\n","pcts"]},{"cell_type":"markdown","source":["Para logralo, lo vamos a dividir en dos pasos. Primero vamos a agregar una columna extra que tenga el porcentaje que acabamos de calcular:"],"metadata":{"id":"oJ5LxIYQAu2N"}},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"nCgd4klV1bum"},"outputs":[],"source":["#--columna donde ponemos el porcentaje de acuerdo a la clase\n","preds = preds.withColumn(\"pcts\",\n","    F.when(preds.label == 0, pcts[0]).otherwise(pcts[1])\n",")\n","\n","preds.show(5)"]},{"cell_type":"markdown","source":["Con esta última columna tenemos todos los ingredientes para hacer la actualización de las nuevas etiquetas e incluir a las predicciones \"confiables\"."],"metadata":{"id":"3FbRmtGsBQpN"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q8x3rKZC1bum"},"outputs":[],"source":["#--actualizamos la variable respuesta.\n","# Si se cumplen las primeras tres condiciones se agrega una etiqueta que\n","# corresponde a una predicción confiable, sino se agregan las etiquetas de la\n","# iteración anterior que puede contener una instancia con etiqueta real o una\n","# instancia sin etiqueta.\n","preds = preds.withColumn(\"label\",\n","    F.when(\n","        (preds.label == 2) &\n","        (preds.prob == 1) &\n","        (F.rand(seed=12345) <= preds.pcts),\n","        preds.prediction).otherwise(preds.label),\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"np2npLiC1bup"},"outputs":[],"source":["#--rectificamos que tengamos un cambio en la distribución de etiquetas para\n","# comprobar que efectivamente tenemos más instancias con etiqueta\n","preds\\\n","    .groupBy('label')\\\n","    .count()\\\n","    .sort('label')\\\n","    .show()"]},{"cell_type":"markdown","source":["Finalmente juntamos todos estos ingredientes en una sola función:"],"metadata":{"id":"SicD9x9EDORk"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"V47bmvgV1bup"},"outputs":[],"source":["def self_training(train_features, max_iter=10, seed=12345,\n","                  num_classes=2, max_depth=5):\n","\n","    # definimos el modelo que vamos a utilizar\n","    dt = DecisionTreeClassifier(maxDepth=max_depth, labelCol=\"label\")\n","\n","    # obtenemos la distribución de clases de las muestras con etiquetas\n","    class_distrib = df_count(train_features.filter(\"label != 2\"), \"label\")\n","\n","    for i in range(max_iter):\n","        labeled = train_features.filter(\"label != 2\")\n","\n","        print(f\"Iteration: {i} - labeled size: {labeled.count()}\")\n","\n","        # Entrenamiento\n","        model = dt.fit(labeled)\n","\n","        # Predecir y obtener probabilidades\n","        preds = model.transform(train_features)\n","        preds = preds.withColumn(\"prob\",\n","            F.array_max(vector_to_array(\"probability\"))\n","        )\n","\n","        # numero de muestras que podriamos incorporar\n","        counts = df_count(\n","            preds.filter(\"label == 2 AND prob == 1\"), \"prediction\"\n","        )\n","\n","        # ponemos una condición para detener el ciclo si no hay instancias\n","        # a sustituir o si no hay instancias de todas las clases\n","        if 0 in counts or len(counts) < num_classes:\n","            break\n","\n","        to_add = instances_per_class(class_distrib, counts)\n","        print(f\"Adding {to_add[0]} instances from class 0, \"\n","              f\"and {to_add[1]} from class 1\")\n","\n","        # calculamos el porcentaje de instancias a incluir\n","        pcts = to_add / counts\n","\n","        preds = preds.withColumn(\"pcts\",\n","            F.when(preds.label == 0, pcts[0]).otherwise(pcts[1]),\n","        )\n","\n","        preds = preds.withColumn(\"label\",\n","            F.when(\n","                (preds.label == 2) & (preds.prob == 1)\n","                & (F.rand(seed=12345) <= preds.pcts),\n","                preds.prediction).otherwise(preds.label),\n","        )\n","\n","        train_features = preds.select(\"features\", \"output\", \"label\").cache()\n","\n","    return train_features.filter(\"label != 2\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s1mRhLNk1bup"},"outputs":[],"source":["# reset train_features\n","train_features = assembler.transform(train)\n","%time enlarged_labeled = self_training(train_features)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I6dgBkvfDEDr"},"outputs":[],"source":["print(f'Número de instancias del conjunto de datos extendido: {enlarged_labeled.count()}')"]},{"cell_type":"markdown","source":["Con el nuevo conjunto de datos podemos entrenar nuestro modelo y medir su desempeño!!"],"metadata":{"id":"ykM15EXhE7sA"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"H7o7vGO9DEDs"},"outputs":[],"source":["model = dt.fit(enlarged_labeled)\n","preds_trans = model.transform(unlabeled)\n","preds_inductive = model.transform(test_features)\n","\n","print(f\"Precisión en las instancias sin etiquetas del conjunto de entrenamiento = {evaluator.evaluate(preds_trans)}\")\n","print(f\"Precisión en el conjunto de prueba = {evaluator.evaluate(preds_inductive)}\")"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"}},"nbformat":4,"nbformat_minor":0}