{"cells":[{"cell_type":"markdown","metadata":{"tags":[],"id":"VtjFioBF3YqS"},"source":["# Entrenamiento de modelos locales en paralelo con Spark\n","\n","* Utilizaremos la idea de MapReduce (divide y venceras) para entrenar modelos independientes de acuerdo a las particiones de datos que tengamos.\n","\n","* Una vez entrenados, tenemos que combinar sus predicciones para obtener una única respuesta.\n","\n","* Utilizaremos un árbol de decisión de la librería \"sci-kit learn\" pero en principio podemos ocupar casi cualquier \"eager learner\".\n","\n","* Básicamente crearemos un \"tree ensemble\"."]},{"cell_type":"code","source":["!pip install pyspark"],"metadata":{"id":"jGtgBpTD3sPr"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"xArXK9fv3YqV"},"outputs":[],"source":["from pyspark.sql import SparkSession\n","\n","import pyspark.sql.functions as F\n","from pyspark.sql.types import *\n","\n","import pandas as pd\n","from sklearn.tree import DecisionTreeClassifier\n","from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n","from sklearn.metrics import accuracy_score\n","\n","\n","spark = SparkSession \\\n","    .builder \\\n","    .master(\"local[*]\") \\\n","    .getOrCreate()"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"Q1Wel2Gv3ff7"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l-sXB2KH3YqW"},"outputs":[],"source":["#--Definimos un esquema para el csv que vamos a leer\n","#-Sino definimos el esquema Spark lo va inferir con la primera línea,\n","#-lo que puede no ser la mejor opción. Existe un parámetro llamado\n","#-\"samplingRatio\" que utiliza una porción de los datos para inferir el esquema\n","#-pero puede ser muy costoso con grandes datos.\n","\n","schema = StructType(\n","    [\n","        StructField(\"Ex01\", FloatType(), True),\n","        StructField(\"Ex02\", FloatType(), True),\n","        StructField(\"Ex03\", FloatType(), True),\n","        StructField(\"Ex04\", FloatType(), True),\n","        StructField(\"Project\", FloatType(), True),\n","        StructField(\"Question 1\", FloatType(), True),\n","        StructField(\"Question 2\", FloatType(), True),\n","        StructField(\"Question 3\", FloatType(), True),\n","        StructField(\"Question 4\", FloatType(), True),\n","        StructField(\"Exam\", FloatType(), True),\n","        StructField(\"Total\", FloatType(), True),\n","    ]\n",")"]},{"cell_type":"code","source":["#--Data set que vamos a leer\n","INPUT_PATH = '/content/drive/MyDrive/data_sets/marks.csv'"],"metadata":{"id":"dnrSpV8C4Lgf"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3HGhv2kb3YqW"},"outputs":[],"source":["#--leemos el archivo CSV\n","df = spark.read.format('csv')\\\n","    .option(\"header\", 'true')\\\n","    .schema(schema)\\\n","    .load(INPUT_PATH)\n","\n","#--creamos una variable respuesta binaria\n","df = df.withColumn('response',\n","                   F.when(df.Total<70, 'not-first')\\\n","                        .otherwise('first'))\n","\n","#--eliminamos las columnas que no necesitamos\n","df = df.drop(\"Question 1\")\\\n","       .drop(\"Question 2\")\\\n","       .drop(\"Question 3\")\\\n","       .drop(\"Question 4\")\\\n","       .drop(\"Exam\")\\\n","       .drop(\"Total\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V0T9GuZF3YqX"},"outputs":[],"source":["df.show(2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K6-FfNR-3YqY"},"outputs":[],"source":["#--dividimos los datos en conjunto de entrenamiento y prueba\n","train_df, test_df = df.randomSplit([0.7, 0.3], seed=42)"]},{"cell_type":"markdown","source":["El número de modelos que vamos a entrenar dependerá del número de particiones que tengamos en nuestros datos.\n","\n","Mayor número de particiones, mayor paralelización pero menor cantidad de datos para cada modelo."],"metadata":{"id":"uRqEyWWJDD1e"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ptd2qeKj3YqY"},"outputs":[],"source":["#--En nuestro caso al ser un data set pequeño, vamos a dividir\n","#-el train set en 3 partes y el de validación en dos partes\n","10, 30, 100\n","\n","train_rdd = train_df.rdd.repartition(3)\n","test_rdd  = test_df.rdd.repartition(2)"]},{"cell_type":"markdown","source":["El nombre de las columnas será utilizado para crear pandas dataFrames que sean homogeneos dentro de cada \"worker\" por lo que esta variable debe estar disponible para todos, debe ser una variable global. Si trabajamos con \"notebooks\" basta asignar el nombre de las columnas a una variable"],"metadata":{"id":"tVD9CxXzDvXs"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"sRLXlr9c3YqY"},"outputs":[],"source":["column_names = df.columns"]},{"cell_type":"markdown","metadata":{"id":"fm_-2pzp3YqY"},"source":["## Entrenamiento del modelo en paralelo\n","\n","Definimos una función que será la encargada de hacer el entrenamiento. Está función se mandará a todos los \"workers\" y cada uno entrenara un modelo de forma independiente.\n","\n","El resultado sera una lista de modelos entrenados con diferentes particiones de la data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"opo0XYIe3YqZ"},"outputs":[],"source":["def build_model(partition_data_it):\n","\n","    #-Tenemos que transformar la data a pandas\n","    partition_data_df = pd.DataFrame(partition_data_it, columns=column_names)\n","\n","    #-Definimos el modelo que deseamos ocupar\n","    clf = DecisionTreeClassifier(random_state=0, max_depth=2)\n","\n","    #-Dividimos los datos en atributos y variable respuesta\n","    X_train = partition_data_df.iloc[:, :-1]\n","    y_train = partition_data_df[\"response\"]\n","\n","    #-Entrenamos el modelo\n","    model = clf.fit(X_train.values, y_train.values)\n","\n","    return [model]"]},{"cell_type":"markdown","source":["Utilizamos \"mapPartitions\" para entrenar nuestros modelos en lugar del clásico \"fit\".\n","\n","__mapPartitions__: aplica una función a cada partición, la función recibe un \"iterador\" y regresa otro \"iterador\"."],"metadata":{"id":"1Keb4jKXFaSY"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"tmZTklDE3YqZ"},"outputs":[],"source":["#--realizamos el entrenamiento y traemos todos los modelos al node \"driver\"\n","models = train_rdd.mapPartitions(build_model).collect()\n","\n","print(f'Número de modelos entrenados: {len(models)}')"]},{"cell_type":"markdown","metadata":{"tags":[],"id":"cmAVoNcr3YqZ"},"source":["## Realizar predicciones en paralelo\n","\n","En este ejemplo tenemos 3 modelos por lo que cada uno de ellos deberá hacer una predicción para cada una de las muestras y al final debemos combinar las predicciones para obtener una predicción por muestra.\n","\n","Los modelos están en el \"driver\", para hacer las predicciones debemos mandarlos a los \"workers\". En este ejemplo estamos usando los modelos como una variable global debido a que son \"pequeños\". Si los modelos son grandes entonces debemos usar un \"broadcasting\"."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DtNAt4Nn3YqZ"},"outputs":[],"source":["#--Definimos una función que va a tomar una muestra (fila de nuestro data set)\n","#-y va a regresar una lista con las predicciones de cada modelo\n","def predict(instance):\n","    X = instance[:-1]\n","    return [m.predict([X])[0] for m in models]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ywrq88wx3YqZ"},"outputs":[],"source":["#--probamos la función y vemos la respuesta de las primeras n filas\n","test_rdd.map(predict).take(3)"]},{"cell_type":"markdown","source":["Necesitamos definir una forma de combinar las salidas de cada modelo para dar una respuesta única por muestra o instancia.\n","\n","La forma más sencilla en clasificación, y la forma que vamos a explorar en este notebook, es por mayoría de votos.\n","\n","Otras formas pueden ser un promedio de las probabilidades o promedios ponderados."],"metadata":{"id":"XI0eCD8IKfUh"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"9bIHnMWb3YqZ"},"outputs":[],"source":["#--definimos la función que hará el trabajo de combinar las respuestas.\n","#-La estrategía será definir un diccionario y contar cuantos votos hay de\n","#-cada clase y elegir la clase con más votos como respuesta final\n","\n","def agg_predictions(preds):\n","    #--definimos el diccionario\n","    predictions = { \"first\": 0, \"not-first\" : 0 }\n","\n","    #--contamos los elementos\n","    for elem in preds:\n","        predictions[elem]+= 1\n","\n","    #--regresamos solamente la llave del valor máximo\n","    return max(predictions, key=predictions.get)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x4RXeCkE3YqZ"},"outputs":[],"source":["#--probamos la función anterior\n","test_rdd.map(predict).map(agg_predictions).take(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R4YxkGTq3Yqa"},"outputs":[],"source":["#--definimos una función que encapsule las dos funciones anteriores y\n","#-de formato a los resultados tal que podamos tenerlos en un spark dataFrame:\n","#-unir los atributos, la variable respuesta real y la predicción en una sola\n","#-fila\n","\n","def transform(instance):\n","    return Row(**instance.asDict(),\\\n","               raw_prediction=agg_predictions(predict(instance)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RS_RziBw3Yqa"},"outputs":[],"source":["#--hacemos las predicciones\n","prediction = test_rdd.map(transform).toDF()\n","prediction.show(2)"]},{"cell_type":"markdown","source":["### Evaluación de modelo"],"metadata":{"id":"ugKpZMUrOUbF"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"jq-GB8KZ3Yqa"},"outputs":[],"source":["#--transformar las predicciones de string a númericas {0,1}\n","prediction_num = prediction.select(\n","    (prediction[\"response\"] == \"first\").cast(\"double\").alias(\"label\"),\n","    (prediction[\"raw_prediction\"] == \"first\").cast(\"double\").alias(\"pred\"),\n",")\n","\n","acc_evaluator = MulticlassClassificationEvaluator(\n","    metricName=\"accuracy\",\n","    labelCol=\"label\",\n","    predictionCol=\"pred\"\n",")\n","\n","print(f'Accuracy: {acc_evaluator.evaluate(prediction_num):.3f}')"]},{"cell_type":"markdown","source":["## Comparación con un solo modelo de sk-learn"],"metadata":{"id":"RZHcTYpGPZ42"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"AiR_L4tI3Yqa"},"outputs":[],"source":["#--convertimos los datos a pandas\n","train_pd = train_df.toPandas()\n","test_pd = test_df.toPandas()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gv4YQYgo3Yqa"},"outputs":[],"source":["#--definimos el modelos\n","clf = DecisionTreeClassifier(random_state=0, max_depth=2)\n","\n","#--dividimos los atributos y la variable respuesta\n","X_train = train_pd.iloc[:, :-1]\n","y_train = train_pd[\"response\"]\n","\n","#--entrenamos el clasificador\n","clf.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XwCgXfqz3Yqb"},"outputs":[],"source":["#--separamos atributos y variable respuesta del test set\n","X_test = test_pd.iloc[:, :-1]\n","\n","#--realizamos la predicciones\n","y_pred = clf.predict(X_test)\n","\n","#--medimos la precisión\n","y_test = test_pd['response']\n","print(f'Accuracy sk-learn model: {accuracy_score(y_test, y_pred):.3f}')"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}